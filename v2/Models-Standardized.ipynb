{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5402e508-d129-420b-862a-28c99e72367f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c88e6b-607a-423e-9ad3-87cbb0d60462",
   "metadata": {},
   "source": [
    "## Precision or Recall?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40300137-9671-4524-983a-5ef2454cc35c",
   "metadata": {},
   "source": [
    "It is important to determine what measure of accuracy we want to use to validate our model. In our case I am going to choose to use precision.\n",
    "\n",
    "Why?\n",
    "\n",
    "Well, lets look at what precision measures. We would be looking at the number of observations that have been correctly subscribed against all of the predicted subscribed values <b>(total Y / total Y obs)</b>, i.e. of all the observations that were predicted as Y, which ones were correct?\n",
    "\n",
    "If we were looking at recall, we would look at <b>total Y correct / total Y</b>, meaning we would also consider the observations that were predicted as Y but were actually N.\n",
    "\n",
    "We don't particularly care if we incorrectly classify a Y because if we predict them to be a N and they turn out to be a Y, then happy days, but what we really care about are the clients that were predicted to be a Y but turned out to be a N because this will affect future planning for our revenue figures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0549d4a8-e5c6-40c6-b038-5557d8268123",
   "metadata": {},
   "source": [
    "## Working with Standardized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f062a840-fc21-4cb5-94f6-028f75693472",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('data/train/x_train_stand.csv').values\n",
    "y_train = pd.read_csv('data/train/y_train_stand.csv').values.flatten()\n",
    "\n",
    "X_test = pd.read_csv('data/test/x_test_stand.csv').values\n",
    "y_test = pd.read_csv('data/test/y_test_stand.csv').values.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afa0534-ecb7-48b6-9394-5cd73a15eaa6",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a82321ed-6df7-4fc0-a5d4-82f2cfbdb22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Actual</th>\n",
       "      <th>Negative</th>\n",
       "      <td>7991</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>1050</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Prediction         \n",
       "                  Negative Positive\n",
       "Actual Negative       7991        2\n",
       "       Positive       1050        0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_clf = LogisticRegression(random_state=0, solver='lbfgs', max_iter=130)\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = lr_clf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score\n",
    "\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_pred_lr),\n",
    "    columns=pd.MultiIndex.from_product([['Prediction'], ['Negative', 'Positive']]),\n",
    "    index=pd.MultiIndex.from_product([['Actual'], ['Negative', 'Positive']])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "14ad5cb6-0f2b-442f-a551-188f7b51a2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7991 records were correctly predicted negative (true negative)\n",
      "0 records were correctly predicted positive (true positives)\n",
      "1050 records were incorrectly predicted negative (false negative)\n",
      "2 records were incorrectly predicted positive (false positive)\n",
      "-----------------------------\n",
      "Accuracy: 88.37%\n",
      "Precision: 0.00%\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_lr).ravel()\n",
    "print('{} records were correctly predicted negative (true negative)'.format(tn))\n",
    "print('{} records were correctly predicted positive (true positives)'.format(tp))\n",
    "print('{} records were incorrectly predicted negative (false negative)'.format(fn))\n",
    "print('{} records were incorrectly predicted positive (false positive)'.format(fp))\n",
    "print('-----------------------------')\n",
    "print('Accuracy: {:.2f}%'.format(accuracy_score(y_test, y_pred_lr) * 100))\n",
    "print('Precision: {:.2f}%'.format(precision_score(y_test, y_pred_lr) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505e7ded-7b28-44b6-89c8-11130a607abb",
   "metadata": {},
   "source": [
    "### K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "589a7b7d-56c9-4de7-9652-8d1de5c0b49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Actual</th>\n",
       "      <th>Negative</th>\n",
       "      <td>7789</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>923</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Prediction         \n",
       "                  Negative Positive\n",
       "Actual Negative       7789      204\n",
       "       Positive        923      127"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5, weights='uniform', metric='minkowski', p=2)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_knn = knn_clf.predict(X_test)\n",
    "\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_pred_knn),\n",
    "    columns=pd.MultiIndex.from_product([['Prediction'], ['Negative', 'Positive']]),\n",
    "    index=pd.MultiIndex.from_product([['Actual'], ['Negative', 'Positive']])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4f53cacd-8659-469e-b059-a8d832831816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7789 records were correctly predicted negative (true negative)\n",
      "127 records were correctly predicted positive (true positives)\n",
      "923 records were incorrectly predicted negative (false negative)\n",
      "204 records were incorrectly predicted positive (false positive)\n",
      "-----------------------------\n",
      "Accuracy: 87.54%\n",
      "Precision: 38.37%\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_knn).ravel()\n",
    "print('{} records were correctly predicted negative (true negative)'.format(tn))\n",
    "print('{} records were correctly predicted positive (true positives)'.format(tp))\n",
    "print('{} records were incorrectly predicted negative (false negative)'.format(fn))\n",
    "print('{} records were incorrectly predicted positive (false positive)'.format(fp))\n",
    "print('-----------------------------')\n",
    "print('Accuracy: {:.2f}%'.format(accuracy_score(y_test, y_pred_knn) * 100))\n",
    "print('Precision: {:.2f}%'.format(precision_score(y_test, y_pred_knn) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3ee609-03cd-4289-a658-2a1b36a48b42",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2e8fd08f-461b-4b17-aa7f-ec10084d922b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Actual</th>\n",
       "      <th>Negative</th>\n",
       "      <td>7993</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>1050</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Prediction         \n",
       "                  Negative Positive\n",
       "Actual Negative       7993        0\n",
       "       Positive       1050        0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_clf = SVC(kernel='linear', random_state=0)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = svm_clf.predict(X_test)\n",
    "\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_pred_svm),\n",
    "    columns=pd.MultiIndex.from_product([['Prediction'], ['Negative', 'Positive']]),\n",
    "    index=pd.MultiIndex.from_product([['Actual'], ['Negative', 'Positive']])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "957806cb-1842-4d17-b3fe-13227ef90f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7993 records were correctly predicted negative (true negative)\n",
      "0 records were correctly predicted positive (true positives)\n",
      "1050 records were incorrectly predicted negative (false negative)\n",
      "0 records were incorrectly predicted positive (false positive)\n",
      "-----------------------------\n",
      "Accuracy: 88.39%\n",
      "Precision: 0.00%\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_svm).ravel()\n",
    "print('{} records were correctly predicted negative (true negative)'.format(tn))\n",
    "print('{} records were correctly predicted positive (true positives)'.format(tp))\n",
    "print('{} records were incorrectly predicted negative (false negative)'.format(fn))\n",
    "print('{} records were incorrectly predicted positive (false positive)'.format(fp))\n",
    "print('-----------------------------')\n",
    "print('Accuracy: {:.2f}%'.format(accuracy_score(y_test, y_pred_svm) * 100))\n",
    "print('Precision: {:.2f}%'.format(precision_score(y_test, y_pred_svm, zero_division=0) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72867db-a592-4f1d-8da8-cd8e4271c8d6",
   "metadata": {},
   "source": [
    "## Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "893f1b18-2e1a-450f-acee-0252bb69e42c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Actual</th>\n",
       "      <th>Negative</th>\n",
       "      <td>7993</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>1050</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Prediction         \n",
       "                  Negative Positive\n",
       "Actual Negative       7993        0\n",
       "       Positive       1050        0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "ksvm_clf = SVC(kernel='rbf', random_state=0)\n",
    "ksvm_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_ksvm = ksvm_clf.predict(X_test)\n",
    "\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_pred_ksvm),\n",
    "    columns=pd.MultiIndex.from_product([['Prediction'], ['Negative', 'Positive']]),\n",
    "    index=pd.MultiIndex.from_product([['Actual'], ['Negative', 'Positive']])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "08ecfb9d-6a21-44ff-9e1a-e95e96e25644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7993 records were correctly predicted negative (true negative)\n",
      "0 records were correctly predicted positive (true positives)\n",
      "1050 records were incorrectly predicted negative (false negative)\n",
      "0 records were incorrectly predicted positive (false positive)\n",
      "-----------------------------\n",
      "Accuracy: 88.39%\n",
      "Precision: 0.00%\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_ksvm).ravel()\n",
    "print('{} records were correctly predicted negative (true negative)'.format(tn))\n",
    "print('{} records were correctly predicted positive (true positives)'.format(tp))\n",
    "print('{} records were incorrectly predicted negative (false negative)'.format(fn))\n",
    "print('{} records were incorrectly predicted positive (false positive)'.format(fp))\n",
    "print('-----------------------------')\n",
    "print('Accuracy: {:.2f}%'.format(accuracy_score(y_test, y_pred_ksvm) * 100))\n",
    "print('Precision: {:.2f}%'.format(precision_score(y_test, y_pred_ksvm, zero_division=0) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b424427-d8d1-4621-bace-d0fa5c20e9e7",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9dd647c2-8246-4b0f-b45b-35e6bb6abf75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Actual</th>\n",
       "      <th>Negative</th>\n",
       "      <td>7146</td>\n",
       "      <td>847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>820</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Prediction         \n",
       "                  Negative Positive\n",
       "Actual Negative       7146      847\n",
       "       Positive        820      230"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb_clf = GaussianNB()\n",
    "gnb_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gnb = gnb_clf.predict(X_test)\n",
    "\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_pred_gnb),\n",
    "    columns=pd.MultiIndex.from_product([['Prediction'], ['Negative', 'Positive']]),\n",
    "    index=pd.MultiIndex.from_product([['Actual'], ['Negative', 'Positive']])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4d80be1b-1650-446b-bd8a-e642efe8f10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7146 records were correctly predicted negative (true negative)\n",
      "230 records were correctly predicted positive (true positives)\n",
      "820 records were incorrectly predicted negative (false negative)\n",
      "847 records were incorrectly predicted positive (false positive)\n",
      "-----------------------------\n",
      "Accuracy: 81.57%\n",
      "Precision: 21.36%\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_gnb).ravel()\n",
    "print('{} records were correctly predicted negative (true negative)'.format(tn))\n",
    "print('{} records were correctly predicted positive (true positives)'.format(tp))\n",
    "print('{} records were incorrectly predicted negative (false negative)'.format(fn))\n",
    "print('{} records were incorrectly predicted positive (false positive)'.format(fp))\n",
    "print('-----------------------------')\n",
    "print('Accuracy: {:.2f}%'.format(accuracy_score(y_test, y_pred_gnb) * 100))\n",
    "print('Precision: {:.2f}%'.format(precision_score(y_test, y_pred_gnb) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1fa515-84aa-4248-80db-bb2388938ec2",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "311e72b9-63fc-48b8-a89c-dfe194fa088c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Actual</th>\n",
       "      <th>Negative</th>\n",
       "      <td>7249</td>\n",
       "      <td>744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>699</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Prediction         \n",
       "                  Negative Positive\n",
       "Actual Negative       7249      744\n",
       "       Positive        699      351"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dt = dt_clf.predict(X_test)\n",
    "\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_pred_dt),\n",
    "    columns=pd.MultiIndex.from_product([['Prediction'], ['Negative', 'Positive']]),\n",
    "    index=pd.MultiIndex.from_product([['Actual'], ['Negative', 'Positive']])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fb179419-76bf-4714-a7cd-deab94248017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7249 records were correctly predicted negative (true negative)\n",
      "351 records were correctly predicted positive (true positives)\n",
      "699 records were incorrectly predicted negative (false negative)\n",
      "744 records were incorrectly predicted positive (false positive)\n",
      "-----------------------------\n",
      "Accuracy: 84.04%\n",
      "Precision: 32.05%\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_dt).ravel()\n",
    "print('{} records were correctly predicted negative (true negative)'.format(tn))\n",
    "print('{} records were correctly predicted positive (true positives)'.format(tp))\n",
    "print('{} records were incorrectly predicted negative (false negative)'.format(fn))\n",
    "print('{} records were incorrectly predicted positive (false positive)'.format(fp))\n",
    "print('-----------------------------')\n",
    "print('Accuracy: {:.2f}%'.format(accuracy_score(y_test, y_pred_dt) * 100))\n",
    "print('Precision: {:.2f}%'.format(precision_score(y_test, y_pred_dt) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb19c8ed-74b5-489c-826f-a27a162badf0",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c7d23842-ef98-403d-b696-2bdb2b7c8eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Actual</th>\n",
       "      <th>Negative</th>\n",
       "      <td>7249</td>\n",
       "      <td>744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>699</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Prediction         \n",
       "                  Negative Positive\n",
       "Actual Negative       7249      744\n",
       "       Positive        699      351"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=10, criterion='entropy', random_state=0)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = dt_clf.predict(X_test)\n",
    "\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_pred_rf),\n",
    "    columns=pd.MultiIndex.from_product([['Prediction'], ['Negative', 'Positive']]),\n",
    "    index=pd.MultiIndex.from_product([['Actual'], ['Negative', 'Positive']])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ced87d66-0b91-48dc-9dd3-b8bc5f4ffe6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7249 records were correctly predicted negative (true negative)\n",
      "351 records were correctly predicted positive (true positives)\n",
      "699 records were incorrectly predicted negative (false negative)\n",
      "744 records were incorrectly predicted positive (false positive)\n",
      "-----------------------------\n",
      "Accuracy: 84.04%\n",
      "Precision: 32.05%\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_rf).ravel()\n",
    "print('{} records were correctly predicted negative (true negative)'.format(tn))\n",
    "print('{} records were correctly predicted positive (true positives)'.format(tp))\n",
    "print('{} records were incorrectly predicted negative (false negative)'.format(fn))\n",
    "print('{} records were incorrectly predicted positive (false positive)'.format(fp))\n",
    "print('-----------------------------')\n",
    "print('Accuracy: {:.2f}%'.format(accuracy_score(y_test, y_pred_rf) * 100))\n",
    "print('Precision: {:.2f}%'.format(precision_score(y_test, y_pred_rf) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b270cdc9-458c-4341-bb61-26cf73425221",
   "metadata": {},
   "source": [
    "The results have not differed much between the two methods of scaling. The best performing models remain to be:\n",
    "- Decision Tree\n",
    "- Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c355e5b-449e-46f0-950c-74740b4bb98e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
