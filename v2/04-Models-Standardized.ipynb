{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5402e508-d129-420b-862a-28c99e72367f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c88e6b-607a-423e-9ad3-87cbb0d60462",
   "metadata": {},
   "source": [
    "## Precision or Recall?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40300137-9671-4524-983a-5ef2454cc35c",
   "metadata": {},
   "source": [
    "It is important to determine what measure of accuracy we want to use to validate our model. In our case I am going to choose to use precision.\n",
    "\n",
    "Why?\n",
    "\n",
    "Well, lets look at what precision measures. We would be looking at the number of observations that have been correctly subscribed against all of the predicted subscribed values <b>(total Y / total Y obs)</b>, i.e. of all the observations that were predicted as Y, which ones were correct?\n",
    "\n",
    "If we were looking at recall, we would look at <b>total Y correct / total Y</b>, meaning we would also consider the observations that were predicted as Y but were actually N.\n",
    "\n",
    "We don't particularly care if we incorrectly classify a Y because if we predict them to be a N and they turn out to be a Y, then happy days, but what we really care about are the clients that were predicted to be a Y but turned out to be a N because this will affect future planning for our revenue figures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0549d4a8-e5c6-40c6-b038-5557d8268123",
   "metadata": {},
   "source": [
    "## Working with Standardized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f062a840-fc21-4cb5-94f6-028f75693472",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('data/train/x_train_stand.csv').values\n",
    "y_train = pd.read_csv('data/train/y_train_stand.csv').values.flatten()\n",
    "\n",
    "X_test = pd.read_csv('data/test/x_test_stand.csv').values\n",
    "y_test = pd.read_csv('data/test/y_test_stand.csv').values.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afa0534-ecb7-48b6-9394-5cd73a15eaa6",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a82321ed-6df7-4fc0-a5d4-82f2cfbdb22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Actual</th>\n",
       "      <th>Negative</th>\n",
       "      <td>4993</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>385</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Prediction         \n",
       "                  Negative Positive\n",
       "Actual Negative       4993     3000\n",
       "       Positive        385      665"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_clf = LogisticRegression(random_state=0, solver='lbfgs', max_iter=130)\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = lr_clf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_pred_lr),\n",
    "    columns=pd.MultiIndex.from_product([['Prediction'], ['Negative', 'Positive']]),\n",
    "    index=pd.MultiIndex.from_product([['Actual'], ['Negative', 'Positive']])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14ad5cb6-0f2b-442f-a551-188f7b51a2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4993 records were correctly predicted negative (true negative)\n",
      "665 records were correctly predicted positive (true positives)\n",
      "385 records were incorrectly predicted negative (false negative)\n",
      "3000 records were incorrectly predicted positive (false positive)\n",
      "-----------------------------\n",
      "Accuracy: 62.57%\n",
      "Precision: 18.14%\n",
      "Recall: 63.33%\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_lr).ravel()\n",
    "print('{} records were correctly predicted negative (true negative)'.format(tn))\n",
    "print('{} records were correctly predicted positive (true positives)'.format(tp))\n",
    "print('{} records were incorrectly predicted negative (false negative)'.format(fn))\n",
    "print('{} records were incorrectly predicted positive (false positive)'.format(fp))\n",
    "print('-----------------------------')\n",
    "print('Accuracy: {:.2f}%'.format(accuracy_score(y_test, y_pred_lr) * 100))\n",
    "print('Precision: {:.2f}%'.format(precision_score(y_test, y_pred_lr) * 100))\n",
    "print('Recall: {:.2f}%'.format(recall_score(y_test, y_pred_lr) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505e7ded-7b28-44b6-89c8-11130a607abb",
   "metadata": {},
   "source": [
    "### K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "589a7b7d-56c9-4de7-9652-8d1de5c0b49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Actual</th>\n",
       "      <th>Negative</th>\n",
       "      <td>7053</td>\n",
       "      <td>940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>714</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Prediction         \n",
       "                  Negative Positive\n",
       "Actual Negative       7053      940\n",
       "       Positive        714      336"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5, weights='uniform', metric='minkowski', p=2)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_knn = knn_clf.predict(X_test)\n",
    "\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_pred_knn),\n",
    "    columns=pd.MultiIndex.from_product([['Prediction'], ['Negative', 'Positive']]),\n",
    "    index=pd.MultiIndex.from_product([['Actual'], ['Negative', 'Positive']])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f53cacd-8659-469e-b059-a8d832831816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7053 records were correctly predicted negative (true negative)\n",
      "336 records were correctly predicted positive (true positives)\n",
      "714 records were incorrectly predicted negative (false negative)\n",
      "940 records were incorrectly predicted positive (false positive)\n",
      "-----------------------------\n",
      "Accuracy: 81.71%\n",
      "Precision: 26.33%\n",
      "Recall: 32.00%\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_knn).ravel()\n",
    "print('{} records were correctly predicted negative (true negative)'.format(tn))\n",
    "print('{} records were correctly predicted positive (true positives)'.format(tp))\n",
    "print('{} records were incorrectly predicted negative (false negative)'.format(fn))\n",
    "print('{} records were incorrectly predicted positive (false positive)'.format(fp))\n",
    "print('-----------------------------')\n",
    "print('Accuracy: {:.2f}%'.format(accuracy_score(y_test, y_pred_knn) * 100))\n",
    "print('Precision: {:.2f}%'.format(precision_score(y_test, y_pred_knn) * 100))\n",
    "print('Recall: {:.2f}%'.format(recall_score(y_test, y_pred_knn) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3ee609-03cd-4289-a658-2a1b36a48b42",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e8fd08f-461b-4b17-aa7f-ec10084d922b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Actual</th>\n",
       "      <th>Negative</th>\n",
       "      <td>4678</td>\n",
       "      <td>3315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>379</td>\n",
       "      <td>671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Prediction         \n",
       "                  Negative Positive\n",
       "Actual Negative       4678     3315\n",
       "       Positive        379      671"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_clf = SVC(kernel='linear', random_state=0)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = svm_clf.predict(X_test)\n",
    "\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_pred_svm),\n",
    "    columns=pd.MultiIndex.from_product([['Prediction'], ['Negative', 'Positive']]),\n",
    "    index=pd.MultiIndex.from_product([['Actual'], ['Negative', 'Positive']])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "957806cb-1842-4d17-b3fe-13227ef90f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4678 records were correctly predicted negative (true negative)\n",
      "671 records were correctly predicted positive (true positives)\n",
      "379 records were incorrectly predicted negative (false negative)\n",
      "3315 records were incorrectly predicted positive (false positive)\n",
      "-----------------------------\n",
      "Accuracy: 59.15%\n",
      "Precision: 16.83%\n",
      "Recall: 63.90%\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_svm).ravel()\n",
    "print('{} records were correctly predicted negative (true negative)'.format(tn))\n",
    "print('{} records were correctly predicted positive (true positives)'.format(tp))\n",
    "print('{} records were incorrectly predicted negative (false negative)'.format(fn))\n",
    "print('{} records were incorrectly predicted positive (false positive)'.format(fp))\n",
    "print('-----------------------------')\n",
    "print('Accuracy: {:.2f}%'.format(accuracy_score(y_test, y_pred_svm) * 100))\n",
    "print('Precision: {:.2f}%'.format(precision_score(y_test, y_pred_svm) * 100))\n",
    "print('Recall: {:.2f}%'.format(recall_score(y_test, y_pred_svm) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72867db-a592-4f1d-8da8-cd8e4271c8d6",
   "metadata": {},
   "source": [
    "## Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "893f1b18-2e1a-450f-acee-0252bb69e42c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Actual</th>\n",
       "      <th>Negative</th>\n",
       "      <td>7560</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>844</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Prediction         \n",
       "                  Negative Positive\n",
       "Actual Negative       7560      433\n",
       "       Positive        844      206"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "ksvm_clf = SVC(kernel='rbf', random_state=0)\n",
    "ksvm_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_ksvm = ksvm_clf.predict(X_test)\n",
    "\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_pred_ksvm),\n",
    "    columns=pd.MultiIndex.from_product([['Prediction'], ['Negative', 'Positive']]),\n",
    "    index=pd.MultiIndex.from_product([['Actual'], ['Negative', 'Positive']])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08ecfb9d-6a21-44ff-9e1a-e95e96e25644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7560 records were correctly predicted negative (true negative)\n",
      "206 records were correctly predicted positive (true positives)\n",
      "844 records were incorrectly predicted negative (false negative)\n",
      "433 records were incorrectly predicted positive (false positive)\n",
      "-----------------------------\n",
      "Accuracy: 85.88%\n",
      "Precision: 32.24%\n",
      "Recall: 19.62%\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_ksvm).ravel()\n",
    "print('{} records were correctly predicted negative (true negative)'.format(tn))\n",
    "print('{} records were correctly predicted positive (true positives)'.format(tp))\n",
    "print('{} records were incorrectly predicted negative (false negative)'.format(fn))\n",
    "print('{} records were incorrectly predicted positive (false positive)'.format(fp))\n",
    "print('-----------------------------')\n",
    "print('Accuracy: {:.2f}%'.format(accuracy_score(y_test, y_pred_ksvm) * 100))\n",
    "print('Precision: {:.2f}%'.format(precision_score(y_test, y_pred_ksvm, zero_division=0) * 100))\n",
    "print('Recall: {:.2f}%'.format(recall_score(y_test, y_pred_ksvm) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b424427-d8d1-4621-bace-d0fa5c20e9e7",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dd647c2-8246-4b0f-b45b-35e6bb6abf75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Actual</th>\n",
       "      <th>Negative</th>\n",
       "      <td>4331</td>\n",
       "      <td>3662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>370</td>\n",
       "      <td>680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Prediction         \n",
       "                  Negative Positive\n",
       "Actual Negative       4331     3662\n",
       "       Positive        370      680"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb_clf = GaussianNB()\n",
    "gnb_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gnb = gnb_clf.predict(X_test)\n",
    "\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_pred_gnb),\n",
    "    columns=pd.MultiIndex.from_product([['Prediction'], ['Negative', 'Positive']]),\n",
    "    index=pd.MultiIndex.from_product([['Actual'], ['Negative', 'Positive']])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d80be1b-1650-446b-bd8a-e642efe8f10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4331 records were correctly predicted negative (true negative)\n",
      "680 records were correctly predicted positive (true positives)\n",
      "370 records were incorrectly predicted negative (false negative)\n",
      "3662 records were incorrectly predicted positive (false positive)\n",
      "-----------------------------\n",
      "Accuracy: 55.41%\n",
      "Precision: 15.66%\n",
      "Recall: 64.76%\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_gnb).ravel()\n",
    "print('{} records were correctly predicted negative (true negative)'.format(tn))\n",
    "print('{} records were correctly predicted positive (true positives)'.format(tp))\n",
    "print('{} records were incorrectly predicted negative (false negative)'.format(fn))\n",
    "print('{} records were incorrectly predicted positive (false positive)'.format(fp))\n",
    "print('-----------------------------')\n",
    "print('Accuracy: {:.2f}%'.format(accuracy_score(y_test, y_pred_gnb) * 100))\n",
    "print('Precision: {:.2f}%'.format(precision_score(y_test, y_pred_gnb) * 100))\n",
    "print('Recall: {:.2f}%'.format(recall_score(y_test, y_pred_gnb) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1fa515-84aa-4248-80db-bb2388938ec2",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "311e72b9-63fc-48b8-a89c-dfe194fa088c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Actual</th>\n",
       "      <th>Negative</th>\n",
       "      <td>7220</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>701</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Prediction         \n",
       "                  Negative Positive\n",
       "Actual Negative       7220      773\n",
       "       Positive        701      349"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dt = dt_clf.predict(X_test)\n",
    "\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_pred_dt),\n",
    "    columns=pd.MultiIndex.from_product([['Prediction'], ['Negative', 'Positive']]),\n",
    "    index=pd.MultiIndex.from_product([['Actual'], ['Negative', 'Positive']])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb179419-76bf-4714-a7cd-deab94248017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7220 records were correctly predicted negative (true negative)\n",
      "349 records were correctly predicted positive (true positives)\n",
      "701 records were incorrectly predicted negative (false negative)\n",
      "773 records were incorrectly predicted positive (false positive)\n",
      "-----------------------------\n",
      "Accuracy: 83.70%\n",
      "Precision: 31.11%\n",
      "Recall: 33.24%\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_dt).ravel()\n",
    "print('{} records were correctly predicted negative (true negative)'.format(tn))\n",
    "print('{} records were correctly predicted positive (true positives)'.format(tp))\n",
    "print('{} records were incorrectly predicted negative (false negative)'.format(fn))\n",
    "print('{} records were incorrectly predicted positive (false positive)'.format(fp))\n",
    "print('-----------------------------')\n",
    "print('Accuracy: {:.2f}%'.format(accuracy_score(y_test, y_pred_dt) * 100))\n",
    "print('Precision: {:.2f}%'.format(precision_score(y_test, y_pred_dt) * 100))\n",
    "print('Recall: {:.2f}%'.format(recall_score(y_test, y_pred_dt) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb19c8ed-74b5-489c-826f-a27a162badf0",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7d23842-ef98-403d-b696-2bdb2b7c8eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Actual</th>\n",
       "      <th>Negative</th>\n",
       "      <td>7220</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>701</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Prediction         \n",
       "                  Negative Positive\n",
       "Actual Negative       7220      773\n",
       "       Positive        701      349"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=10, criterion='entropy', random_state=0)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = dt_clf.predict(X_test)\n",
    "\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_pred_rf),\n",
    "    columns=pd.MultiIndex.from_product([['Prediction'], ['Negative', 'Positive']]),\n",
    "    index=pd.MultiIndex.from_product([['Actual'], ['Negative', 'Positive']])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ced87d66-0b91-48dc-9dd3-b8bc5f4ffe6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7220 records were correctly predicted negative (true negative)\n",
      "349 records were correctly predicted positive (true positives)\n",
      "701 records were incorrectly predicted negative (false negative)\n",
      "773 records were incorrectly predicted positive (false positive)\n",
      "-----------------------------\n",
      "Accuracy: 83.70%\n",
      "Precision: 31.11%\n",
      "Recall: 33.24%\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_rf).ravel()\n",
    "print('{} records were correctly predicted negative (true negative)'.format(tn))\n",
    "print('{} records were correctly predicted positive (true positives)'.format(tp))\n",
    "print('{} records were incorrectly predicted negative (false negative)'.format(fn))\n",
    "print('{} records were incorrectly predicted positive (false positive)'.format(fp))\n",
    "print('-----------------------------')\n",
    "print('Accuracy: {:.2f}%'.format(accuracy_score(y_test, y_pred_rf) * 100))\n",
    "print('Precision: {:.2f}%'.format(precision_score(y_test, y_pred_rf) * 100))\n",
    "print('Recall: {:.2f}%'.format(recall_score(y_test, y_pred_rf) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b270cdc9-458c-4341-bb61-26cf73425221",
   "metadata": {},
   "source": [
    "The results have not differed much between the two methods of scaling. The best performing models remain to be:\n",
    "- Decision Tree\n",
    "- Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4545847-1191-439e-9ba8-69d45dea3024",
   "metadata": {},
   "source": [
    "<b>How can I amend the threshold of my model to focus on precision?</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b776eb-8a7a-4bf1-883a-a2293cf58872",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
